# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
ENVIRONMENT=development

# Logger Configuration
FILE_LOG_LEVEL=info
CONSOLE_LOG_LEVEL=info

# Database Configuration (Primary)
DB_HOST=local-infra-postgres
DB_PORT=5432
DB_USERNAME=
DB_PASSWORD=
DB_DATABASE=cool_rag

# OpenAI Configuration
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_CHAT_MODEL=gpt-4o-mini
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.7

# Self-host VLLM Configuration
VLLM_API_KEY=
VLLM_MODEL=openai/gpt-oss-120b
VLLM_MAX_INPUT_TOKENS=44000
VLLM_MAX_OUTPUT_TOKENS=8000
VLLM_REASONING_EFFORT=medium
VLLM_BASE_URL=

# Documents Configuration
DOCUMENTS_DIR=/workspace/backend/documents

# Retrieval Configuration
# Chunk size & overlap are defined in terms of tokens, not characters
TOP_K_RESULTS=7
SIMILARITY_THRESHOLD=0.4
CHUNK_SIZE=320
CHUNK_OVERLAP=64
EMBEDDING_BATCH_SIZE=20

# MMR (Maximal Marginal Relevance) Configuration
# USE_MMR: Enable MMR algorithm for diverse results (true/false)
# MMR_LAMBDA: Balance between relevance and diversity (0.0-1.0, default 0.5)
#   - 1.0 = pure relevance (same as vector search)
#   - 0.0 = pure diversity
#   - 0.5 = balanced
# MMR_FETCH_K: Number of candidates to fetch before MMR selection (default 20)
USE_MMR=true
MMR_LAMBDA=0.5
MMR_FETCH_K=20

# Token Budget Configuration (Memory Management)
TOKEN_BUDGET_MAX_CONTEXT=16000
TOKEN_BUDGET_MEMORY=4000
TOKEN_BUDGET_RETRIEVAL=8000
TOKEN_BUDGET_OUTPUT=2000
TOKEN_BUDGET_SYSTEM_PROMPT=500
